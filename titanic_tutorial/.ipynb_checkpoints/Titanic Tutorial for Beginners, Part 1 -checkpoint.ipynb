{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Tutorial for Beginners, Part 1: The very basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, this is my first Titanic tutorial. I have the impression that sometimes the available starters tend to be lengthy and include a lot of code, something that might not be great for a newbie. So, I'll try my best to keep the tutorials short and intuitive for beginners. My aim is to make a series of kernels (4 parts), starting from this one, which is a quick approach of loading and understanding our data and submitting the output of a very simple model. I will gradually add more tutorials on more advanced techniques used by competitive Kagglers, such as detailed EDA, local validation, feature engineering, hyperparameter tuning, model stacking, and more. I hope it is useful, thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebooks in the series**:\n",
    "\n",
    "* https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-1\n",
    "* https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-2\n",
    "* https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the default first cell in any Kaggle Kernel, it is handy since it loads the standard Python Data Science stack **NumPy** and **Pandas** libraries. It also lists the available files in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to load and quickly explore our train dataset, the previous cell output helps us to find the file names! To read the dataset, we will use the **read_csv**() Pandas method. Now, the previous listing of our files comes in handy, since we know the input to our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read train data\n",
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "\n",
    "# Have a first look at train data\n",
    "print('Train shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this means that we have 891 rows and 12 columns. Now, let's have a first look at our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at first 5 data observations\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at last 5 data observations\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha, very interesting. We have 891 **observations**, 11 **features**, and our **target** variable, **Survived**.\n",
    "\n",
    "But what are all those variable names? From https://www.kaggle.com/c/titanic/data, we have: \n",
    "* **Survival**  = Survival\n",
    "* **Pclass**    = Ticket class\n",
    "* **Sex**       = Sex \n",
    "* **Age**       = Age in years \n",
    "* **Sibsp**     = # of siblings / spouses aboard the Titanic \n",
    "* **Parch**     = # of parents / children aboard the Titanic \n",
    "* **Ticket**    = Ticket number \n",
    "* **Fare**\t    = Passenger fare \n",
    "* **Cabin**\t    = Cabin number \n",
    "* **Embarked**  = Port of Embarkation \n",
    "\n",
    "Hmmm, a lot of info..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second step is to check for missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look for possible missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good enough, but there is a neater way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort them in descending order!\n",
    "train.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We see that we have missing variables for '**Cabin**', '**Age**',  and '**Embarked**', so we can't use these variables for prediction without dealing with the missing variables first. For a simple but efficient first approach: [Part 2](https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-2) \n",
    "\n",
    "For something a bit more more sophisticated: [Part 3](https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Now we should load our test data. Also, let's have a first look at train and test column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "# Have a first look at test data\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks OK, the only additional column in train is '**Survived**', which is our target variable, i.e. the one we want to actually predict in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check sample submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to make a valid submission, a good habit is to check the sample submission file provided by Kaggle, to become familiar with the needed format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample submission file\n",
    "sample_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n",
    "\n",
    "# Look at the first 5 observations of sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at last 5 observations\n",
    "print(sample_submission.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now it is time to decide what kind of model to use. We can guess by looking at the above output: the variable **'Survived'** seems to be binary... Let's confirm it! Now, there are a lot of Python plotting libraries, but we can't go wrong with **Matplotlib** and **Seaborn**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Countplot for 'Survived' variable\n",
    "sns.countplot(train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, we have a classification problem here, **'Survived'** is binary, with 2 possible values, 0 and 1! So, the first thought would probably be to try a **Logistic Regression** model, which is **THE** fundamental classification algorithm! And the simplest one to start with is a model with only one feature, but which one to choose? Here is a hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Survived', hue = 'Sex', data = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! **'Sex'** looks like a very strong explanatory variable, and it will be our choice for our single feature Logistic Regression model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first simple model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model to our train set. We will use **Scikit-learn**, which is our favourite library when it comes to **Machine Learning**, since it includes every standard **regression**, **classification**, and **clustering** algorithm (**Deep Learning** is a different animal, if you are interested in this area, stay tuned)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit a logistic regression model to our train data, by converting 'Sex' to a dummy variable, to feed it into the model.\n",
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression.fit(X = pd.get_dummies(train['Sex']), y = train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make predictions for our test set! Notice that we quickly transform the '**Sex**' values to numeric ones (dummies) by using the **get_dummies**() pandas method, in order to bring them to a suitable format for our Logistic Regression model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict!\n",
    "test['Survived'] = logisticRegression.predict(pd.get_dummies(test['Sex']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last! Final step: let's make our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test predictions for final submission\n",
    "test[['PassengerId', 'Survived']].to_csv('kaggle_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise: Our simplest model is far from being a weak one, with an **accuracy** equal to 0.76555! This is actually a decent score, especially since we've used just a single feature. For more info about accuracy: [Part 2](https://www.kaggle.com/kernelgenerator/titanic-tutorial-for-beginners-part-2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, here we conclude our intro tutorial, but this is just the start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you like my notebook, I would appreciate an upvote, which will keep me motivated for additional content, thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
